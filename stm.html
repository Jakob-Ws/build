<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="" xml:lang="">
<head>
  <meta charset="utf-8" />
  <meta name="generator" content="pandoc" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
  <title>Stochastische Methoden</title>
  <style>
    code{white-space: pre-wrap;}
    span.smallcaps{font-variant: small-caps;}
    div.columns{display: flex; gap: min(4vw, 1.5em);}
    div.column{flex: auto; overflow-x: auto;}
    div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
    /* The extra [class] is a hack that increases specificity enough to
       override a similar rule in reveal.js */
    ul.task-list[class]{list-style: none;}
    ul.task-list li input[type="checkbox"] {
      font-size: inherit;
      width: 0.8em;
      margin: 0 0.8em 0.2em -1.6em;
      vertical-align: middle;
    }
  </style>
  <link rel="stylesheet" href="resources/style.css" />
  <script
  src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js"
  type="text/javascript"></script>
</head>
<body>
<div class="navbar">
<p><a href="index.html">jakob</a> / <a href="stm.html">stm</a></p>
</div>
<h1 id="stochastische-methoden">Stochastische Methoden</h1>
<p>Der hier folgende Text sind, meine persönlichen Notizen zu der von
mir besuchten Vorlesung zu den Stochastischen Methoden. </p>
<h2 id="inhaltsverzeichnis">Inhaltsverzeichnis</h2>
<ol type="1">
<li><a href="#01">Wahrscheinlichkeitsräume</a></li>
<li><a href="#02">Zufallsvariablen und Verteilungen</a></li>
<li><a href="#03">Bedingte Wahrscheinlichkeiten und stochastische
Unabhängigkeit</a> (#03)</li>
<li><a href="#a0">Aufgabenblatt 00</a></li>
<li><a href="#a1">Aufgabenblatt 01</a></li>
<li><a href="#a8">Aufgabenblatt 08</a></li>
<li><a href="#cm">Concept-Map</a></li>
</ol>
<h2 id="01">Wahrscheinlichkeitsräume</h2>
<p>Im Folgenden gilt:</p>
<ol type="1">
<li><span class="math inline">\(\Omega\)</span> ist die
<em>Ergebnismenge</em>, in ihr sind alle möglichen <em>Ergebnisse</em>
<span class="math inline">\(\omega\)</span> Enthalten.</li>
<li>Teilemengen <span class="math inline">\(A\)</span> von <span
class="math inline">\(\Omega\)</span> nennen wir <em>Ereignisse</em>,
denen wir eine Wahrscheinlichkeit <span class="math inline">\(P(A)  \in
[0,1]\)</span> zuordnen.</li>
</ol>
<p><strong>Definition - <span
class="math inline">\(\sigma\)</span>-algebra</strong> Ein Mengensystem
<span class="math inline">\(\mathcal{A}\)</span> von Teilmengen von
<span class="math inline">\(\Omega\)</span>, nennt man <span
class="math inline">\(\sigma\)</span>-algebra wenn:</p>
<ul>
<li><span class="math inline">\(\Omega \in \mathcal{A}\)</span></li>
<li><span class="math inline">\(A\in \mathcal{A} \Rightarrow
\overline{A} \in \mathcal{A}\)</span></li>
<li><span class="math inline">\((A_n)_{n\in \mathbb{N}} \in \mathcal{A}
\Rightarrow \bigcup_{n\in \mathbb{N}}(A_n)_{n\in \mathbb{N}} \in
\mathcal{A}\)</span></li>
</ul>
<p>Das Paar (<span class="math inline">\(\Omega,\mathcal{A}\)</span>)
nennt man einen <em>Messraum</em>, falls <span
class="math inline">\(\mathcal{A}\)</span> eine Sigmaalgebra ist.</p>
<p>Hieraus folgt direkt:</p>
<ol type="1">
<li><span class="math inline">\(\emptyset \in \mathcal{A}\)</span>, da
<span class="math inline">\(\overline{\Omega} = \emptyset\)</span>
gilt.</li>
<li><span class="math inline">\(A_1,A_2,\cdots,A_n \in \mathcal{A}
\Rightarrow \bigcap_{n\in \mathbb{N}} A_n\in \mathcal{A}\)</span>, da
per Punkt drei deren Vereinigung enthalten ist, ist auch das Komplement
der Vereinigung enthalten, was mit DeMorgan einfach der Schnitt
ist.</li>
<li><span class="math inline">\(A_1.A_2 \in \mathcal{A} \Rightarrow A_1
\cup A_2 \in \mathcal{A}\land  A_1 \cap A_2 \in \mathcal{A}\)</span>,
wegen Punkt drei und DeMorgan.</li>
</ol>
<p><strong>Satz - Der Schnitt von abzählbar unendlich vielen
Sigmaalgebren</strong> Sind <span
class="math inline">\(\mathcal{A}_i\)</span> mit <span
class="math inline">\(i\in I\)</span> Sigmaalgebren so ist deren Schnitt
<span class="math inline">\(\bigcap_{i\in I} \mathcal{A}_i\)</span>
wieder eine Sigmaalgebra.</p>
<p><strong>Definition - Erzeugt <span
class="math inline">\(\sigma\)</span>-Algebra</strong> Sei <span
class="math inline">\(\mathcal{E} \subseteq P(\Omega)\)</span>. Man
nennt <span class="math inline">\(\sigma({\mathcal{E}})\)</span> die von
<span class="math inline">\(\mathcal{E}\)</span> erzeugte Sigmaalgebra.
D.h. <span class="math inline">\(\sigma({\mathcal{E}})\)</span> ist die
kleinste Sigmaalgebra, die <span
class="math inline">\({\mathcal{E}}\)</span> enthält. Gilt <span
class="math inline">\(\sigma({\mathcal{E}})=\mathcal{A}\)</span> so ist
<span class="math inline">\(\mathcal{E}\)</span> ein <em>Erzeuger</em>
<span class="math inline">\(\mathcal{A}\)</span>. Es gilt hierbei immer
<span
class="math display">\[\sigma({\mathcal{E}})=\bigcap\{\mathcal{A}:\mathcal{A}
\text{ ist Sigmaalgebra und } \mathcal{E}\subseteq
\mathcal{A}\}.\]</span></p>
<p>Eine hier zu erwähnend Sigmaalgebra ist die Borelsche <span
class="math inline">\(\sigma\)</span>-Algebra <span
class="math inline">\(\mathcal{B}^d\)</span> in <span
class="math inline">\(\mathbb{R}^d\)</span>. Sie wird von den offenen
Mengen <span class="math inline">\(\mathcal{O}\)</span> im <span
class="math inline">\(\mathbb{R}^d\)</span> erzeugt und spielt im
Folgenden eine wichtige Rolle.</p>
<p><strong>Definition - Wahrscheinlichkeitsraum</strong> Ein Messraum
(<span class="math inline">\(\Omega,\mathcal{A}\)</span>) mit einer
Abbildung <span class="math inline">\(P:\mathcal{A} \to [0,1]\)</span>
nennt man einen <em>Wahrscheinlichkeitsraum</em>, wenn <span
class="math inline">\(P\)</span> ein Wahrscheinlichkeitsmaß ist,
d.h.:</p>
<ul>
<li><span class="math inline">\(P(\Omega)=1\)</span></li>
<li><span class="math inline">\(P\)</span> muss <span
class="math inline">\(\sigma\)</span>-additiv sein also: <span
class="math display">\[P(\bigcup_{n\in\mathbb{N}}A_n)=\sum_{n\in\mathbb{N}}P(A_n)
\quad \text{für paarweise disjunkte }A_n \in \mathcal{A}\]</span></li>
</ul>
<p><strong>Satz - Rechenregeln im Wahrscheinlichkeitsraum</strong> Seine
<span class="math inline">\(A_1,\cdots,A_n,A,B \in \mathcal{A}\)</span>,
dann gilt:</p>
<ol type="1">
<li><span class="math inline">\(P(\emptyset)=0\)</span></li>
<li><span class="math inline">\(\sigma\)</span>-additivität vor allem
<span class="math inline">\(P(\overline{A})=1-P(A)\)</span></li>
<li><span class="math inline">\(P(A\cup B) = P(A)+P(B)-P(A\cap
B)\)</span></li>
<li><span class="math inline">\(P(A) \leq P(B)\)</span> wenn <span
class="math inline">\(A \subseteq B\)</span> (Monotonie)</li>
<li><span class="math inline">\(P(\bigcup_{n\in\mathbb{N}}A_n)\leq
\sum_{n\in\mathbb{N}}P(A_n)\)</span> (Subadditivität)</li>
</ol>
<p>Der dritte Punkt lässt sich für abzählbar unendliche viele <span
class="math inline">\(A_i\)</span> folgendermaßen erweitern.</p>
<p><strong>Satz - Siebformel, Einschluss-Ausschluss-Formel</strong>
Seien <span class="math inline">\(A_1,\cdots,A_n \in
\mathcal{A}\)</span>, dann gilt:</p>
<p><span class="math display">\[P(A_1\cup\cdots\cup A_n)=
\sum_{k=1}^n(-1)^{k+1}\cdot \sum_{1\leq i_1 &lt; \cdots&lt;i_k\leq n
}P(A_{i1}\cap \cdots \cap A_{ik})\]</span></p>
<p><strong>Definition - Nullmengen</strong></p>
<ol type="1">
<li>In einem Wahrscheinlichkeitsraum nennt man eine Menge <span
class="math inline">\(N \subseteq P(\Omega)\)</span> eine
<em>Nullmenge</em>, wenn ein <span class="math inline">\(A \in
\mathcal{A}\)</span> existiert mit <span
class="math inline">\(P(A)=0\)</span> und <span class="math inline">\(N
\subseteq A\)</span> gilt.</li>
<li>Gilt eine Eigenschaft für alle <span class="math inline">\(\omega
\in \Omega\setminus N\)</span> so gelte sie fast sicher.</li>
</ol>
<p>Es gilt zudem, dass abzählbare Vereinigungen von Nullmengen wieder
Nullmengen sind.</p>
<h2 id="02">Zufallsvariablen und Verteilungen</h2>
<p><strong>Definition - Zufallsvariable</strong> Gegeben seine zwei
Messräume <span class="math inline">\((\Omega, \mathcal{A})\)</span> und
<span class="math inline">\((\Omega&#39;, \mathcal{A}&#39;)\)</span>.
Eine Abbildung <span class="math inline">\(X: \Omega \to
\Omega&#39;\)</span> heißt <em>messbar</em>, wenn <span
class="math display">\[X^{-1}(A&#39;)\in \mathcal{A} \quad \forall
A&#39; \in \mathcal{A&#39;}.\]</span> <span
class="math inline">\(X^{-1}(A&#39;)\)</span> ist hierbei das Urbild von
<span class="math inline">\(A&#39;\)</span> unter X. Handelt es sich bei
<span class="math inline">\((\Omega, \mathcal{A})\)</span> zusätzlich um
einen Wahrscheinlichkeitsraum, so ist <span
class="math inline">\(X\)</span> eine Zufallsvariable.</p>
<p><strong>Definition - Verteilung</strong> Sei <span
class="math inline">\((\Omega, \mathcal{A}),P\)</span> ein
Wahrscheinlichkeitsraum,<span class="math inline">\((\Omega&#39;,
\mathcal{A}&#39;)\)</span> ein Messraum und <span
class="math inline">\(X\)</span>eine Zufallsvariable. So nennt man:
<span class="math display">\[P^X:\mathcal{A&#39;}\to[0,1], A&#39;
\mapsto P(X^{-1}(A&#39;))\]</span> die Verteilung von <span
class="math inline">\(X\)</span>.</p>
<p>Durch die Definition der Verteilung von <span
class="math inline">\(X\)</span> gilt zudem, dass auch <span
class="math inline">\((\Omega&#39;, \mathcal{A}&#39;,P^X)\)</span> ein
Wahrscheinlichkeitsraum ist. Haben zwei Zufallsvariablen die gleiche
Verteilung, so heißen diese identisch verteilt. Das Nachweisen, dass
eine Abbildung eine Zufallsvariable ist, gestaltet sich nicht immer als
einfach, somit hilft folgender Satz.</p>
<p><strong>Satz - Zufallsvariablen</strong> Seien <span
class="math inline">\((\Omega,\mathcal{A},P)\)</span> ein
Wahrscheinlichkeitsraum, <span
class="math inline">\((\Omega&#39;,\mathcal{A&#39;})\)</span> ein
Messraum und <span class="math inline">\(X:\Omega \to
\Omega&#39;\)</span> eine Abbildung. Dann gilt:</p>
<ol type="1">
<li><span class="math inline">\(X\)</span> ist eine Zufallsvariable,
wenn <span class="math inline">\(\mathcal{A}=P(\Omega)\)</span>. Ist
klar, da so jedes Urbild in <span
class="math inline">\(\mathcal{A}\)</span> enthalten ist.</li>
<li>Gilt <span class="math inline">\(\mathcal{A&#39;} =
\sigma(\mathcal{E&#39;})\)</span> für einen Erzeuger <span
class="math inline">\(\mathcal{E&#39;}\subseteq P(\Omega&#39;)\)</span>,
so ist <span class="math inline">\(X\)</span> eine Zufallsvariable, wenn
<span class="math inline">\(X^{-1}(E&#39;)\in \mathcal{A}\)</span> für
alles <span class="math inline">\(E&#39;\in \mathcal{E}\)</span> gilt.
Man muss also nicht ganz <span
class="math inline">\(\mathcal{A&#39;}\)</span> prüfen, sondern nur die
Elemente des Erzeugers <span
class="math inline">\(\mathcal{E&#39;}\)</span>.</li>
<li>Ist <span class="math inline">\(\Omega&#39;=\mathbb{R}\)</span> und
<span class="math inline">\(\mathcal{A&#39;}=\mathcal{B}\)</span>, so
ist <span class="math inline">\(X\)</span> eine Zufallsvariable, wenn
<span class="math display">\[\{X\leq b\}:= \{\omega\in \Omega:
X(\omega)\leq b\}\in \mathcal{A} \quad \forall b \in \mathbb{R}\]</span>
d.h. die Menge aller Werte, die eine Zufallsvariable annehmen kann, die
kleine als <span class="math inline">\(b\)</span> sind muss messbar sein
und das für alle <span class="math inline">\(b\)</span>.</li>
<li>Unter den gleichen Voraussetzungen wie in 3. ist <span
class="math inline">\(X\)</span> auch eine Zufallsvariable, falls <span
class="math inline">\(\Omega&#39; =
\overline{\mathbb{R}}:=[-\infty,\infty]\)</span> mit <span
class="math inline">\(\mathcal{A&#39;}=\overline{\mathcal{B}}:=\sigma(\mathcal{B}\cup\{-\infty\}\cup\{\infty\})\)</span>.</li>
<li>Zufallsvariablen sind zudem auch:
<ul>
<li>stetige Funktionen (mit <span
class="math inline">\(\mathcal{A}=\mathcal{B}\)</span>)</li>
<li>konstante Funktionen</li>
<li>Kompositionen von Zufallsvariablen</li>
<li>Summen, Differenzen, Produkte und Quotienten von
Zufallsvariablen</li>
</ul></li>
</ol>
<p><strong>Definition - Von <span class="math inline">\(X\)</span>
erzeugte Sigmaalgebra</strong> Seien <span
class="math inline">\((\Omega,\mathcal{A},P)\)</span> ein
Wahrscheinlichkeitsraum, <span
class="math inline">\((\Omega&#39;,\mathcal{A&#39;})\)</span> ein
Messraum und <span class="math inline">\(X:\Omega \to
\Omega&#39;\)</span> eine Zufallsvariable. Dann ist <span
class="math inline">\(\sigma(X)\)</span> die kleinste Sigmaalgebra bzgl.
der <span class="math inline">\(X\)</span> messbar ist. <span
class="math inline">\(\sigma(X)\subseteq \mathcal{A}\)</span> beinhaltet
genau die Ereignisse, über deren Eintreten durch Beobachten von <span
class="math inline">\(X\)</span> entschieden werden kann.</p>
<h3 id="diskrete-verteilungen">Diskrete Verteilungen</h3>
<p><strong>Definition - Diskret</strong> Ein Wahrscheinlichkeitsraum und
das Wahrscheinlichkeitsmaß heißen <em>diskret</em>, falls <span
class="math inline">\(\Omega\)</span> höchstens abzählbar ist und <span
class="math inline">\(\mathcal{A}=P(\Omega)\)</span> ist. Das Tupel
<span class="math inline">\((p_\omega)_{\omega \in \Omega}\)</span> mit
<span class="math inline">\(p_{\omega} = P(\{\omega\})\)</span> nennt
man Wahrscheinlichkeitsvektor. Besitzt eine Zufallsvariable eine
diskrete Verteilung, so nennt man sie diskret.</p>
<p>In diskreten Wahrscheinlichkeitsräumen gilt <span
class="math display">\[P(A)=\sum_{\omega \in A}p_{\omega}\]</span></p>
<p><strong>Satz - Urnenmodelle</strong></p>
<table>
<colgroup>
<col style="width: 33%" />
<col style="width: 33%" />
<col style="width: 33%" />
</colgroup>
<thead>
<tr>
<th>Urnenmodelle</th>
<th>Reihenfolge</th>
<th>ohne Reihenfolge</th>
</tr>
</thead>
<tbody>
<tr>
<td><strong>zurücklegen</strong></td>
<td>Mögliche Ausgänge <span class="math display">\[A_1=\{(x_1,\cdots
x_n)\}: x_i \in \{1,\cdots,N\}\Rightarrow \|A_1\|=N^n\]</span></td>
<td>Geht nicht</td>
</tr>
<tr>
<td><strong>ohne zurücklegen</strong></td>
<td>Mögliche Ausgänge<span class="math display">\[A_2=\{(x_1,\cdots
x_n)\}: x_i \in \{1,\cdots,N\}, \text{alle Einträge pwv.}\Rightarrow
\|A_2\|=\frac{N!}{(N-n)!}\]</span></td>
<td>Mögliche Ausgänge <span class="math display">\[A_3 =\{(x_1,\cdots
x_n)\}: x_i \in \{1,\cdots,N\},\text{Einträge geoordnet von klein nach
groß}\Rightarrow \|A_3\|=\binom{N}{n}\]</span></td>
</tr>
</tbody>
</table>
<p><strong>Beispiel - Einige diskrete Verteilungen</strong></p>
<ol type="1">
<li>Laplaceraum und Gleichverteilung: Ist <span
class="math inline">\(\Omega\)</span> endlich und <span
class="math inline">\(p_\omega=1/|\Omega|\)</span> so gilt <span
class="math display">\[P(A)=\frac{|A|}{|\Omega|}.\]</span></li>
<li>Hypergeometrische Verteilung <span
class="math inline">\(\text{Hyp}(N,M,n)\)</span>: Sei <span
class="math inline">\(N\in \mathbb{N}\)</span> und <span
class="math inline">\(n,M \in \{0,\cdots ,N\}\)</span>, der
Wahrscheinlichkeitsvektor ist gegeben durch <span
class="math display">\[p_k=\text{Hyp}(N,M,n)(k)=\frac{\binom{M}{k}\binom{N-M}{n-k}}{\binom{N}{n}}.\]</span>
Die Interpretation ist eine Ziehung ohne Zurücklegen und ohne Beachtung
der Reihenfolge, in der wir eine Grundgesamtheit von <span
class="math inline">\(N\)</span> haben, von denen <span
class="math inline">\(M\)</span> das Merkmal <span
class="math inline">\(E\)</span> tragen. Es wird eine Stichprobe der
Größe <span class="math inline">\(n\)</span> gezogen. Von diesen tragen
<span class="math inline">\(k\)</span> das Merkmal <span
class="math inline">\(E\)</span> z. B. Lotto.</li>
<li>Binomialverteilung <span
class="math inline">\(\text{Bin}(n,p)\)</span>: Sei <span
class="math inline">\(n\in \mathbb{N}\)</span> und <span
class="math inline">\(p \in (0,1)\)</span>, der
Wahrscheinlichkeitsvektor ist gegeben durch <span
class="math display">\[p_k=\text{Bin}(n,p)(k)=\binom{n}{k}p^k(1-p)^{n-k}.\]</span>
Die Interpretation sind <span class="math inline">\(n\)</span>
unabhängige Zufallsexperimente mit Ausgang Erfolg/Misserfolg (oder
ja/nein, 0/1), und <span class="math inline">\(p\)</span> ist die
Erfolgswahrscheinlichkeit, dass in einem Experiment der gewünschte
Ausgang auftritt.</li>
<li>Bernoulliverteilung <span
class="math inline">\(\text{Ber}(p)\)</span>: Spezialfall von 3. mit
<span class="math inline">\(n=1\)</span>. Also gilt <span
class="math inline">\(\text{Ber}(p)=\text{Bin}(1,p)\)</span>. Sie ist
das diskrete Analogon zur Exponentialverteilung.</li>
<li>Poissonverteilung <span
class="math inline">\(\text{Poi}(\lambda)\)</span>: Für <span
class="math inline">\(\lambda &gt; 0\)</span> ist der
Wahrscheinlichkeitsvektor gegeben durch <span class="math display">\[p_k
=\text{Poi}(\lambda)(k)=\frac{\lambda^k}{k!}e^{-\lambda}. \]</span> Die
Poissonverteilung kommt zum Einsatz, wenn wir unabhängige, gleichartige
Ereignisse pro Zeiteinheit zählen. Dabei kann <span
class="math inline">\(\lambda\)</span> als die mittlere Anzahl dieser
Ereignisse pro Zeiteinheit angesehen werden und <span
class="math inline">\(\text{Poi}(\lambda)(k)\)</span> als die
Wahrscheinlichkeit, dass gerade <span class="math inline">\(k\)</span>
Ereignisse im beobachteten Zeitintervall vorkommen.</li>
</ol>
<h3 id="stetige-verteilungen">Stetige Verteilungen</h3>
<p><strong>Satz - Wahrscheinlichkeitsmaß</strong> Sei <span
class="math inline">\(\Omega \subseteq \mathbb{R}^d, \Omega \in
\mathcal{B}^d\)</span> und <span class="math inline">\(f:\mathbb{R} \to
[0,\infty]\)</span> eine messbare Funktion mit <span
class="math inline">\(\int_\Omega f(x)\mathrm{d}x =1\)</span>. Durch
<span class="math display">\[P(A)=\int_A f(x)\mathrm{d}x\]</span>, für
alle <span class="math inline">\(A \in \mathcal{B}^d_\Omega\)</span>wird
dadurch ein Wahrscheinlichkeitsmaß definiert.</p>
<p><strong>Definition - Dichte &amp; und stetig Verteilung</strong> Sei
<span class="math inline">\(\Omega\)</span> eine Borelsche Menge im
<span class="math inline">\(\mathbb{R}^d\)</span>, <span
class="math inline">\(P\)</span> ein Wahrscheinlichkeitsmaß auf <span
class="math inline">\((\Omega,\mathcal{B}_\Omega^d)\)</span> und <span
class="math inline">\(f: \Omega \to [0,\infty]\)</span> sei messbar mit
<span class="math inline">\(P(A)=\int_Af(x)\mathrm{d}x\)</span>. Dann
heißt <span class="math inline">\(f\)</span> <em>Dichte</em> von <span
class="math inline">\(P\)</span>. Ist <span
class="math inline">\(X\)</span> eine Zufallsvariable mit Werten im
<span class="math inline">\(\mathbb{R}^d\)</span> und hat <span
class="math inline">\(P^X\)</span> eine Dichte, so nennt man <span
class="math inline">\(X\)</span> <em>stetig</em>.</p>
<p><strong>Beispiel - Einige stetige Verteilungen</strong></p>
<ol type="1">
<li>Stetige Gleichverteilung <span
class="math inline">\(\text{U}_\Omega\)</span>: Auf <span
class="math inline">\(\Omega \in \mathcal{B}^d,
\lambda^d(\Omega)&gt;0\)</span> (Flächeninhalt von <span
class="math inline">\(\Omega\)</span>) gilt für die Dichte <span
class="math display">\[\frac{1}{\lambda^d(\Omega)}\mathbf{1}_\Omega.\]</span></li>
<li>Exponentialverteilung <span
class="math inline">\(\text{Exp}(\beta)\)</span>: Auf <span
class="math inline">\(\Omega =\mathbb{R}\)</span> mit Parameter <span
class="math inline">\(\beta&gt;0\)</span> ist sie gegen durch die Dichte
<span class="math display">\[f:\mathbb{R} \to [0,\infty] \quad x \mapsto
\beta e^{-\beta x}\mathbf{1}_{[0,\infty)}(x).\]</span> Anwendung findet
die Exponentialverteilung bei der Modellierung von Lebensdauern,
Wartezeiten und Schadenshöhen. Es ist die einzige stetige gedächtnislose
Verteilung, d.h. für <span class="math inline">\(X  \sim
\text{Exp}(\beta)\)</span> gilt <span
class="math display">\[\frac{P(X&gt;s+t)}{P(X&gt;s)}= P (X&gt;t) \quad
\forall s,t \geq 0.\]</span> Z.b. gehen wir davon aus die Lebensdauer
eine Glühbirne ist Exponentialverteilt. Diese Glühbirne hat bis jetzt
100 Stunden (<span class="math inline">\(s\)</span>) problemlos
funktioniert. Die Gedächtnislosigkeit bedeutet, dass die
Wahrscheinlichkeit, dass sie noch weitere 10 Stunden hält (<span
class="math inline">\(t\)</span>), genauso groß ist, wie wenn man von
einer neuen Glühbirne ausgeht. Die 100 Stunden, die sie bereits
geleuchtet hat, spielen also keine Rolle.</li>
<li>Normalverteilung <span
class="math inline">\(\text{N}(\mu,\sigma^2)\)</span>: Mit <span
class="math inline">\(\mu \in \mathbb{R}\)</span> und <span
class="math inline">\(\sigma&gt; 0\)</span> auf <span
class="math inline">\(\Omega = \mathbb{R}\)</span> ist sie durch
folgende Dichte gegeben: <span
class="math display">\[\varphi_{\mu,\sigma^2}:\mathbb{R}\to[0,\infty)
\quad x \mapsto
\frac{1}{\sqrt{2\pi\sigma^2}}e^{-\frac{1}{2}(\frac{x-\mu}{\sigma})^2}.\]</span>Hierbei
nennt man <span class="math inline">\(\mu\)</span> den Lageparameter (wo
ist das Maximum?) und <span class="math inline">\(\sigma\)</span> einen
Streuungsparameter. Ist <span class="math inline">\(\mu = 0,
\sigma=1\)</span> so nennt man sie <em>Standardnormalverteilung.</em>
Anwendung findet die Normalverteilung bei der Modellierung von
Messfehlern.</li>
</ol>
<h3 id="verteilungsfunktion-quantile">Verteilungsfunktion &amp;
Quantile</h3>
<p><strong>Definition - Verteilungsfunktion</strong> In einem
Wahrscheinlichkeitsraum <span
class="math inline">\((\mathbb{R},\mathcal{B},P)\)</span> heißt <span
class="math display">\[F:\mathbb{R}\to [0,1] \quad x \mapsto F(x)=
P((-\infty,x])\]</span> die <em>Verteilungsfunktion</em> von <span
class="math inline">\(P\)</span>. Ist <span
class="math inline">\(X\)</span> eine reellwertige Zufallsvariable,
bezeichnet man <span class="math inline">\(P^X\)</span> mit <span
class="math inline">\(F^X\)</span> also <span
class="math display">\[F^X=P^X((-\infty,x])=P^X(X\leq x).\]</span></p>
<p>Es folgen nun zwei der wichtigen Eigenschaften, die eine
Verteilungsfunktion erfüllen muss.</p>
<p><strong>Satz - Eigenschaften der Verteilungsfunktion</strong> Die
Verteilungsfunktion <span class="math inline">\(F\)</span> eines
Wahrscheinlichkeitsmaßes <span class="math inline">\(P\)</span> ist
monoton wachsend und rechtsseitig stetig mit: <span
class="math display">\[F^-(-\infty)=0 \quad\land\quad F^+(\infty)=1
.\]</span> Es gilt auch die Umkehrung.</p>
<p><strong>Definition - Alpha-Quantil</strong> Für gegeben Verteilung
<span class="math inline">\(P\)</span> mit der Verteilungsfunktion <span
class="math inline">\(F\)</span> und <span class="math inline">\(\alpha
\in (0,1)\)</span> nennt man ein <span
class="math inline">\(q_\alpha\)</span>-Quantil von <span
class="math inline">\(P\)</span>, wenn <span
class="math display">\[F(q_\alpha-)\leq\alpha\leq
F(q_\alpha).\]</span></p>
<p><strong>Satz - Zusammenhang zwischen Dichte und
Verteilungsfunktion</strong> Ist <span
class="math inline">\(F:\mathbb{R}\to[0,1]\)</span>, zusätzlich zu den
obigen Eigenschaften noch stetig differenzierbar mit <span
class="math inline">\(F&#39;=f\)</span>, so hat das
Wahrscheinlichkeitsmaß <span class="math inline">\(P\)</span> mit dichte
<span class="math inline">\(f\)</span> die Verteilungsfunktion <span
class="math inline">\(F\)</span>.</p>
<h2 id="03">Bedingte Wahrscheinlichkeiten und stochastische
Unabhängigkeit</h2>
<p><strong>Definition - Bedingte Wahrscheinlichkeit</strong> Sei <span
class="math inline">\((\Omega,\mathcal{A},P)\)</span> ein
Wahrscheinlichkeitsraum und <span class="math inline">\(B\in
\mathcal{A}\)</span> mit <span class="math inline">\(P(B)&gt;0\)</span>.
Man nennt <span class="math display">\[P(A|B)=\frac{P(A \cap
B)}{P(B)}\]</span> die <em>bedingte Wahrscheinlichkeit von A gegeben
B</em>. Allgemeiner heißt <span class="math inline">\(P(\cdot|B):
\mathcal{A}\to[0,1]\)</span> die <em>bedingte Verteilung gegeben <span
class="math inline">\(B\)</span></em>.</p>
<p><strong>Satz - Satz der totalen Wahrscheinlichkeit &amp; der Satz von
Bayes</strong> Sei <span
class="math inline">\((\Omega,\mathcal{A},P)\)</span> ein
Wahrscheinlichkeitsraum. Für eine Zerlegung <span
class="math inline">\((B_n)_{n\in \mathbb{N}}\)</span> von <span
class="math inline">\(\Omega\)</span> (d.h. p.w Disjunkte <span
class="math inline">\(B_n\)</span> mit <span
class="math inline">\(\bigcup B_n = \Omega\)</span>) gilt:</p>
<ol type="1">
<li>Für <span class="math inline">\(A\in \mathcal{A}\)</span> <span
class="math display">\[P(A)=\sum_{n\in
\mathbb{N}}P(A|B_n)P(B_n)\]</span></li>
<li>Für <span class="math inline">\(A\in \mathcal{A}\)</span> mit <span
class="math inline">\(P(A)&gt;0\)</span> <span
class="math display">\[P(B_k|A)=\frac{P(A|B_k)P(B_k)}{\sum_{n\in
\mathbb{N}}P(A|B_n)P(B_n)}\]</span></li>
</ol>
<p><em>Beweis:</em></p>
<ol type="1">
<li><span
class="math inline">\(P(A)=P(A\cap\Omega)=P(A\cap\bigcup_{n\in\mathbb{N}}B_n)=P(\bigcup_{n\in\mathbb{N}}A\cap
B_n)=\sum_{n\in \mathbb{N}}P(A\cap B_n)=\sum_{n\in
\mathbb{N}}P(A|B_n)P(B_n)\)</span></li>
<li><span class="math inline">\(P(B_k|A)=\frac{P(B_k\cap
A)}{P(A)}=\frac{P(A|B_k)P(B_k)}{P(A)}=\frac{P(A|B_k)P(B_k)}{\sum_{n\in
\mathbb{N}}P(A|B_n)P(B_n)}\)</span></li>
</ol>
<h3 id="stochastische-unabhängigkeit">Stochastische Unabhängigkeit</h3>
<p><strong>Definition - Stochastische Unabhängigkeit</strong> Sei <span
class="math inline">\((\Omega,\mathcal{A},P)\)</span> ein
Wahrscheinlichkeitsraum. Ereignisse <span class="math inline">\(A,B\in
\mathcal{A}\)</span> heißen <em>stochastisch unabhängig</em>, wenn <span
class="math display">\[P(A\cap B)=P(A)P(B).\]</span> Ferner nennt man
eine Familie von Ereignissen <span class="math inline">\((A_i)_{i\in
I}\)</span> stochastisch unabhängig, wenn für jede Teilmenge <span
class="math inline">\(J\subseteq I\)</span> gilt <span
class="math display">\[P(\bigcap_{i\in J}A_i)=\prod_{i \in
J}P(A_i).\]</span></p>
<p><strong>Definition - unabhängige Zufallsvariablen</strong> Eine
Familie von Zufallsvariablen <span class="math inline">\((X_i)_{i\in
I}\)</span> auf <span class="math inline">\((\Omega,\mathcal{A},P),
X_i\)</span> mit werten in <span
class="math inline">\((\Omega_i,\mathcal{A_i})\)</span> heißt
<em>unabhängig</em>, wenn für jede Wahl <span
class="math inline">\(A_i\in \mathcal{A_i}\)</span> die Ereignisse <span
class="math inline">\((\{X_i \in A_i\})_{i\in I}\)</span> unabhängig
sind. Besitzen die Zufallsvariablen noch die gleiche Verteilung, so
nennt man sie <em>unabhängig identisch</em>.</p>
<h3 id="gemeinsame-verteilung">Gemeinsame Verteilung</h3>
<p><strong>Definition - Gemeinsame Verteilung</strong> Sei <span
class="math inline">\((\Omega,\mathcal{A},P)\)</span> ein
Wahrscheinlichkeitsraum und seien <span class="math inline">\(X_i:
\Omega \to \mathbb{R}, i \cdots,d\)</span> mit <span
class="math inline">\(d\in \mathbb{N}\)</span>, Zufallsvariablen. Man
nennt die Verteilung <span
class="math inline">\(P^X=P^{(X_1,\cdots,X_d)}\)</span> der
Zufallsvariablen <span class="math display">\[X:\Omega \to \mathbb{R}^d
\quad X(\omega)=(X_1(\omega),\cdots, X_d(\omega) )^T\]</span> die
<em>gemeinsame Verteilung</em> von <span class="math inline">\(X_1,
\cdots, X_d.\)</span>Die <span class="math inline">\(P_i^X\)</span> sind
<em>Randverteilungen</em> von <span
class="math inline">\(X\)</span>.</p>
<h3 id="die-verteilung-von-summen-unabhängiger-zufallsvariablen">Die
Verteilung von Summen unabhängiger Zufallsvariablen</h3>
<p><strong>Satz - Summe von Zufallsvariablen</strong></p>
<p>Seien <span class="math inline">\(X,Y: \Omega\to \mathbb{R}\)</span>
unabhängige Zufallsvariablen.</p>
<ol type="1">
<li>Sind <span class="math inline">\(X,Y\)</span> diskret, mit Werten in
<span class="math inline">\(\mathbb{Z}\)</span>, so ist die Verteilung
von <span class="math inline">\(X+Y\)</span> gegeben durch <span
class="math display">\[P^{X+Y}=P^X
*P^Y=\sum_{i\in\mathbb{Z}}P^X(i)P^Y(m-i) \quad m\in
\mathbb{Z}.\]</span></li>
<li>Haben die Verteilungen von <span class="math inline">\(X,Y\)</span>
stückweise stetige Dichten <span class="math inline">\(f^X,f^Y\)</span>,
so gilt <span class="math inline">\(P^{X+Y}=P^X*P^Y\)</span>, auf <span
class="math inline">\(\mathbb{R}\)</span> gegeben ist durch die Dichte
<span class="math display">\[f^X*f^Y:\mathbb{R}\to[0,\infty) \quad t\to
\int_\mathbb{R} f^Xf^Y(t-x) \mathrm{d}x.\]</span></li>
</ol>
<p><strong>Definition - Faltung</strong> In der Situation vom Satz -
Summen von Zufallsvariablen heißt <span
class="math inline">\(P^X*P^Y\)</span> die <em>Faltung</em> von <span
class="math inline">\(P^X\)</span> und <span
class="math inline">\(P^Y\)</span> sowie die Faltung der Dichten <span
class="math inline">\(f^X\)</span>und <span
class="math inline">\(f^Y\)</span>. Für <span
class="math inline">\(n\geq2\)</span> gilt: <span
class="math display">\[P^X_{*1}=P^X \text{ und }
P^X_{*n}=P^X_{*n-1}*P^X.\]</span></p>
<h2 id="a0">Aufgabenblatt 00</h2>
<p><strong>Aufgabe 0.1 - Ergebnismengen und Ereignisse</strong> Geben
Sie zur Modellierung der folgenden Zufallsexperimente jeweils eine
geeignete Ergebnismenge <span class="math inline">\(\Omega\)</span> an.
Stellen Sie dann die angegebenen Ereignisse als Teilmenge von <span
class="math inline">\(\Omega\)</span> dar.</p>
<ol type="1">
<li>In einer Lostrommel befinden sich 5 Kugeln mit den Nummern
1,2,3,4,5. Es werden zwei Kugeln mit Zurücklegen gezogen. Ereignisse:
<span class="math display">\[
\begin{aligned}A:&amp; \text{ „Die Summe der gezogenen Zahlen beträgt
6.“} \\
B:&amp; \text{ „Die zweite gezogene Zahl ist mindestens doppelt so groß
wie die erste.“} \\
C:&amp; \text{ „Es wird mindestens einmal die Zahl 5 gezogen.“}
\end{aligned}
\]</span>Lösung: <span class="math display">\[\begin{aligned}
\Omega &amp;= \{(a,b)\}=\{1,2,3,4,5\}^2 \quad a,b \in \{1,2,3,4,5\} \\
A&amp;= \{(a,b)|a+b=6\}=\{(1,5),(5,1),(2,4),(4,2),(3,3)\} \\
B&amp;=
\{(a,b)|b\geq2a)\}=\{(1,2),(1,3),(1,4),(1,5),(1,6),(2,4),(2,5),(2,6),(3,6)\}
\\
C&amp;= \{(a,b)|a=5 \lor b=5\} =
\{(1,5),(2,5),(3,5),(4,5),(5,5),(6,5),(5,1),(5,2),(5,3),(5,4),(5,6)\}
\end{aligned}\]</span></li>
<li>In einer Lostrommel befinden sich 5 Kugeln mit den Nummern
1,2,3,4,5. Es werden zwei Kugeln ohne Zurücklegen gezogen. Ereignisse:
<span class="math display">\[
\begin{aligned}A:&amp; \text{ „Die Summe der gezogenen Zahlen beträgt
6.“} \\
B:&amp; \text{ „Die zweite gezogene Zahl ist mindestens doppelt so groß
wie die erste.“} \\
C:&amp; \text{ „Es wird mindestens einmal die Zahl 5 gezogen.“}
\end{aligned}
\]</span>Lösung: <span class="math display">\[\begin{aligned}
\Omega &amp;= \{(a,b)\}=\{1,2,3,4,5\}^2 \quad a,b \in \{1,2,3,4,5\} \\
A&amp;= \{(a,b)|a+b=6\}=\{(1,5),(5,1),(2,4),(4,2)\} \\
B&amp;=
\{(a,b)|b\geq2a)\}=\{(1,2),(1,3),(1,4),(1,5),(1,6),(2,4),(2,5),(2,6),(3,6)\}
\\
C&amp;= \{(a,b)|a=5 \lor b=5\} =
\{(1,5),(2,5),(3,5),(4,5),(6,5),(5,1),(5,2),(5,3),(5,4),(5,6)\}
\end{aligned}\]</span></li>
<li>Sechs Personen, die wir zur Identifikation von 1 bis 6
durchnummerieren, werden durch Auslosen in zwei Dreiergruppen
aufgeteilt. Ereignisse: <span class="math display">\[
\begin{aligned}
A:&amp; \text{ „Person 1 und Person 2 sind in derselben Gruppe.“} \\
B:&amp; \text{ „Person 5 und Person 6 sind in verschiedenen Gruppen.“}
\\
C:&amp; \:\: A\cap B
\end{aligned}
\]</span> Lösung: <span class="math display">\[\begin{aligned}
\Omega &amp;= \{(a,b,c)\}=\{1,2,3,4,5,6\}^3 \quad a,b,c \in
\{1,2,3,4,5,6\}\ \:\&amp;\:\text{pwv}. \\
A&amp;= \{(a,b,c)|(a=1\lor a=2)\land(b=1\lor
b=2)\}=\{(1,2,3),(1,2,4),(1,2,5),(1,2,6),(2,1,3),(2,1,4),(2,1,5),(2,1,6),(\text{alle
wo 1 und 2 nicht drin sind})\} \\
B&amp;= \{(a,b,c)|b\geq2a)\}=\{(1,2,5),(1,2,6), \text{usw...}\} \\
C&amp;= \{(a,b)|a=5 \lor b=5\} =
\{(1,2,5),(1,2,6),(2,1,5),(2,1,6),(3,4,5),(3,4,6),(4,3,5),(4,3,6,)\}
\end{aligned}\]</span> Hier müsste man noch alle Permutationen der
Tripel aufschreiben, was sehr lästig ist, somit bietet es sich eher an
min Mengen zu arbeiten</li>
</ol>
<p><strong>Aufgabe 0.2 - Ereignisse in messbaren Räumen</strong> Sei
<span class="math inline">\((\Omega,\mathcal{A})\)</span> ein messbarer
Raum und <span class="math inline">\(A_1,A_2,\cdots \in
\mathcal{A}\)</span> eine Folge von Ereignissen. Beschreiben Sie die
folgenden Ereignisse mithilfe geeigneter mengentheoretischer
Operationen.</p>
<ol type="1">
<li>Keines der Ereignisse <span
class="math inline">\(A_1,A_2,\cdots\)</span> tritt ein. Lösung: <span
class="math display">\[\bigcap_{i=1}^\infty \overline{A_i}\]</span></li>
<li>Genau eines der Ereignisse <span
class="math inline">\(A_1,A_2,\cdots\)</span> tritt ein. Lösung: <span
class="math display">\[\bigcup_{n=1}^\infty A_n \cap
\bigcap_{\substack{i=1\\i\neq n}}^\infty \overline{A_i}\]</span></li>
<li>Genau zwei der Ereignisse <span
class="math inline">\(A_1,A_2,\cdots\)</span> treten ein. Lösung: <span
class="math display">\[\bigcup_{n=1}^\infty
\bigcup_{\substack{m=1\\m\neq n}}^\infty A_n\cap A_m \cap
\bigcap_{\substack{i=1\\i\neq n\\i\neq m}}^\infty
\overline{A_i}\]</span></li>
</ol>
<p><strong>Aufgabe 0.3 - Beispiel für ein
Wahrscheinlichkeitsmaß</strong> Drei Glühbirnen, von denen jede einzelne
defekt sein kann, werden gleichzeitig eingeschaltet. Definieren Sie für
dieses Zufallsexperiment einen messbaren Raum <span
class="math inline">\((\Omega,\mathcal{A})\)</span>, sodass <span
class="math inline">\(\mathcal{A}\)</span> die Ereignisse <span
class="math display">\[
\begin{aligned}
A_1: &amp; \text{ „Genau zwei Glühbirnen brennen.“,} \\
A_2:&amp; \text{ „Höchstens zwei Glühbirnen brennen.“} \\
\end{aligned}
\]</span> enthält. Ein Wahrscheinlichkeitsmaß <span
class="math inline">\(P\)</span> auf dem Raum <span
class="math inline">\((\Omega,\mathcal{A})\)</span>, soll <span
class="math inline">\(P(A_1) = \frac{2}{5}\)</span> und <span
class="math inline">\(P(A_2) = \frac{4}{5}\)</span> erfüllen. Welche
Wahrscheinlichkeiten können Sie mit diesen Vorgaben dann noch berechnen?
Lösung: <span class="math display">\[\begin{aligned}
\Omega &amp;= \{0,1,2,3\} \quad \text{Anzahl der leuchtenden Glühbirnen}
\\
\mathcal{A} &amp;= P(\Omega) \quad \text{Ganze Potenzmenge} \\
\end{aligned}\]</span> Man kann auch <span
class="math inline">\(\sigma(E)\)</span> als Sigmaalgebra wählen <span
class="math inline">\(E=\{A_1,A_2\}\)</span>. Zusätzlich lassen sich
folgende Wahrscheinlichkeiten bestimmen: <span
class="math display">\[\begin{aligned}
P(\overline{A_1})&amp;=1- \frac{2}{5} = \frac{3}{5}\\
P(\overline{A_2})&amp;=1- \frac{4}{5} = \frac{1}{5} \quad \text{Drei
Glühbirnen brennen.}\\
P(A_1 \cap \overline{A_2}) &amp;= \frac{2}{5}+\frac{1}{5} = \frac{3}{5}
\\
P(\overline{A_1 \cap \overline{A_2}}) &amp;= 1-\frac{3}{5} = \frac{2}{5}
\end{aligned}\]</span></p>
<p><strong>Aufgabe 0.4 - Beispiel für einen
Wahrscheinlichkeitsraum</strong> Wir definieren <span
class="math display">\[\mathcal{A}=\{A\subseteq \mathbb{R}|A \text{ ist
abzählbar oder } \overline{A} \text{ ist abzählar.}\}\]</span> und <span
class="math inline">\(P:\mathcal{A}\to[0,1]\)</span> durch <span
class="math display">\[P(A)= \begin{cases}0, \text{ falls $A$
abzählbar,}\\ 1,  \text{sonst.}\end{cases}\]</span></p>
<ol type="1">
<li>Zeigen Sie zunächst, dass <span
class="math inline">\(\mathcal{A}\)</span> eine <span
class="math inline">\(\sigma\)</span>-Algebra auf <span
class="math inline">\(\Omega = \mathbb{R}\)</span> ist. Lösung: <span
class="math inline">\(\emptyset, \mathbb{R} \in \mathcal{A}\)</span>, da
die Leere-Menge, abzählbar ist und <span
class="math inline">\(\overline{\mathbb{R}}=\emptyset\)</span> abzählbar
ist. Sei <span class="math inline">\(A\in \mathcal{A}\)</span>, so gilt
entweder <span class="math inline">\(A\)</span> oder dessen Komplement
<span class="math inline">\(\overline{A}\)</span> ist abzählbar. Ist
<span class="math inline">\(A\)</span> abzählbar, so gilt <span
class="math inline">\(\overline{A}\in \mathcal{A}\)</span>, da <span
class="math inline">\(\overline{\overline{A}}=A \in
\mathcal{A}\)</span>. Ist <span
class="math inline">\(\overline{A}\)</span> abzählbar. So ist <span
class="math inline">\(\overline{A}\in \mathcal{A}\)</span> da es
abzählbar ist. Sei <span class="math inline">\((A_n)_{n\in\mathbb{N}}
\in \mathcal{A}\)</span>. Falls alle <span
class="math inline">\(A_n\)</span> abzählbar sind, ist auch deren
Schnitt abzählbar. Falls aber mindestens ein <span
class="math inline">\(A_n\)</span> nicht abzählbar ist so ist dessen
Komplement abzählbar. Im folgenden sei <span
class="math inline">\(A_k\)</span> mit <span class="math inline">\(k\in
\mathbb{N}\)</span> nicht abzählbar. Dann gilt: <span
class="math display">\[\overline{\bigcup_{n\in \mathbb{N}} A_n}=
\bigcap_{n\in\mathbb{N}} \overline{A_n}\subseteq \overline{A_k}\]</span>
Hiermit ist gezeigt, dass <span
class="math inline">\(\overline{\bigcup_{n\in \mathbb{N}} A_n}\)</span>
abzählbar ist (Teilmengen von abzählbaren Mengen sind selbst auch
abzählbar). Also <span
class="math display">\[\bigcap_{n\in\mathbb{N}}A_n \in
\mathcal{A}\]</span></li>
<li>Zeigen Sie dann, dass <span
class="math inline">\((\mathbb{R},\mathcal{A},P)\)</span> ein
Wahrscheinlichkeitsraum ist. Lösung Der Teil der Sigmaalgebra wurde in
Punkt eins gezeigt, somit bleibt nur noch zu zeigen das <span
class="math inline">\(P\)</span> ein Wahrscheinlichkeitsmaß ist. Das
<span class="math inline">\(\mathbb{R}\)</span> überabzählbar ist, gilt
<span class="math inline">\(P(\mathbb{R})= 1\)</span>. Seien <span
class="math inline">\(A_n\in \mathcal{A}\)</span> paarweise disjunkt.
Falls alle <span class="math inline">\(A_n\)</span> abzählbar sind gilt
<span class="math display">\[P(\bigcup_{n\in
\mathbb{N}}A_n)=0=0=\sum_{i=1}^\infty 0 =\sum_{i=1}^\infty
P(A_n).\]</span> Existiert nun aber min. <span class="math inline">\(k
\in \mathbb{N}\)</span> das nicht abzählbar ist, muss dessen Komplement
abzählbar sein. Es gilt also <span
class="math display">\[P(\bigcup_{n\in \mathbb{N}}A_n)=1,\]</span> da
sonst auch <span class="math inline">\(A_k\)</span> abzählbar seien
müsste. Zudem gilt <span class="math display">\[\sum_{i=1}^\infty
P(A_n)=\sum_{\substack{i=1\\i\neq k}}^\infty
P(A_n)+P(A_k)=0+1=1.\]</span> Zusammen gilt <span
class="math display">\[P(\bigcup_{n\in \mathbb{N}}A_n)=\sum_{i=1}^\infty
P(A_n).\]</span></li>
</ol>
<h2 id="a1">Aufgabenblatt 01</h2>
<p><strong>Aufgabe 1.1 - Dreimaliges Würfeln</strong> Ein roter, ein
gelber und ein grüner Würfel werden gleichzeitig geworfen. Geben Sie
einen geeigneten Wahrscheinlichkeitsraum für dieses Zufallsexperiment an
und berechnen Sie dann die Wahrscheinlichkeiten der folgenden
Ereignisse: <span class="math display">\[
\begin{aligned}
A:&amp; \text{ „Der rote und der gelbe Würfel zeigen die gleiche
Augenzahl.“}\\
B:&amp; \text{ „Die Augensumme des gelben und des grünen Würfels ist
durch drei teilbar.“}\\
C:&amp; \text{ „Der rote und der grüne Würfel zeigen verschiedene
Augenzahlen.“}
\end{aligned}\]</span>Lösung: Für den Wahrscheinlichkeitsraum <span
class="math inline">\((\Omega,\mathcal{A},P)\)</span> gilt: <span
class="math display">\[
\begin{aligned}
\Omega&amp;=\{1,2,3,4,5,6\}^3=\{(r,g_e,g_r)\} \quad \text{ wobei }
r,g_e,g_r \in \{1,2,3,4,5,6\};\\
|\Omega|&amp;= 6\cdot 6\cdot 6 = 216\\
\mathcal{A}&amp;= P(\Omega) \quad \text{(die ganze Potenzmenge)},\\
P(A) &amp;= \frac{|A|}{|\Omega|} \quad\forall A \in \mathcal{A} \text{
(Laplace-Maß}).
\end{aligned}\]</span>Somit gilt für die Ereignisse <span
class="math inline">\(A,B,C\)</span>:<span
class="math display">\[\begin{aligned}
A &amp;=\{(r,g_e,g_r)|r= g_e\} \Rightarrow |A|=1\cdot 6^2 = 36\\
B &amp;= \{(r,g_e,g_r)|3\mid g_e+ g_r\} \Rightarrow |B| = 6\cdot 12
=72\\
C &amp;= \{(r,g_e,g_r)|r \neq  g_r\} \Rightarrow |C| = 6\cdot 6 \cdot 5
=180.
\end{aligned}\]</span> Somit gilt für die Wahrscheninlichkeiten:<span
class="math display">\[\begin{aligned}
P(A) &amp;=\frac{36}{216}\\
P(B) &amp;=\frac{72}{216}\\
P(C) &amp;=\frac{180}{216}.
\end{aligned}\]</span></p>
<p><strong>Aufgabe 1.2 - Existenz einer minimalen Sigmaalgebra</strong>
Sei <span class="math inline">\(S\subseteq P(\Omega)\)</span> ein
Mengensystem. Zeigen Sie mit den folgenden drei Schritten, dass es eine
minimale <span class="math inline">\(\sigma\)</span>-Algebra auf <span
class="math inline">\(\Omega\)</span> gibt, die <span
class="math inline">\(S\)</span> enthält. Diese <span
class="math inline">\(\sigma\)</span>-Algebra wird dann mit <span
class="math inline">\(\sigma(S)\)</span> bezeichnet und heißt die von
<span class="math inline">\(S\)</span> erzeugte <span
class="math inline">\(\sigma\)</span>-Algebra.</p>
<ol type="1">
<li>Zeigen Sie, dass es eine <span
class="math inline">\(\sigma\)</span>-Algebra auf <span
class="math inline">\(\Omega\)</span> gibt, die <span
class="math inline">\(S\)</span> enthält. Lösung: Zu einem Mengensystem
<span class="math inline">\(S\)</span> ist <span
class="math display">\[\sigma(S)=\bigcap\{\mathcal{A}:\mathcal{A} \text{
ist Sigmaalgebra und } S\subseteq \mathcal{A}\},\]</span> eine solche
Sigmaalgebra. <span class="math inline">\(P(\Omega)\)</span> ginge
natürlich auch.</li>
<li>Zeigen Sie, dass der Schnitt von <span
class="math inline">\(\sigma\)</span>-Algebren, die <span
class="math inline">\(S\)</span> enthalten, wieder eine <span
class="math inline">\(\sigma\)</span>-Algebra ist, die <span
class="math inline">\(S\)</span> enthält. Lösung: <u><span
class="math inline">\(\Omega \in \bigcap_{i\in
I}\mathcal{A_i}\)</span></u>: Da <span
class="math inline">\(\Omega\)</span> in jeder Sigmaalgebra von <span
class="math inline">\(\sigma(S)\)</span> enthalten ist, liegt es auch im
Schnitt derer. <u><span class="math inline">\(A \in \bigcap_{i\in
I}\mathcal{A_i} \Rightarrow \overline{A} \in \bigcap_{i\in
I}\mathcal{A_i}\)</span></u>: Wenn <span class="math inline">\(A \in
\bigcap_{i\in I}\mathcal{A_i}\)</span> ist, dann ist es in jeder <span
class="math inline">\(\mathcal{A}_i\)</span> aus denen <span
class="math inline">\(\bigcap_{i\in I}\mathcal{A_i}\)</span> besteht, da
<span class="math inline">\(\mathcal{A}_i\)</span> alles Sigmaalgebren
sind, ist überall <span class="math inline">\(\overline{A}\)</span>
enthalten, und somit auch im Schnitt derer. (<span
class="math inline">\(A_n)_{n\in \mathbb{N}} \in \bigcap_{i\in
I}\mathcal{A_i} \Rightarrow \bigcup_{n\in \mathbb{N}}(A_n)_{n\in
\mathbb{N}} \in \bigcap_{i\in I}\mathcal{A_i}\)</span>: Da jedes <span
class="math inline">\(A_n\)</span> in <span
class="math inline">\(\bigcap_{i\in I}\mathcal{A_i}\)</span> liegt,
liegt jedes <span class="math inline">\(A_n\)</span> auch in jedem <span
class="math inline">\(\mathcal{A_i}\)</span>. Somit ist <span
class="math inline">\(\bigcup_{n\in \mathbb{N}}(A_n)_{n\in \mathbb{N}}
\in \mathcal{A_i}\)</span> und somit auch im Schnitt aller <span
class="math inline">\(\mathcal{A_i}\)</span></li>
<li>Folgern Sie, dass es eine minimale <span
class="math inline">\(\sigma\)</span>-Algebra auf <span
class="math inline">\(\Omega\)</span> gibt, die <span
class="math inline">\(S\)</span> enthält. Lösung: <span
class="math display">\[\sigma(S)=\bigcap\{\mathcal{A}:\mathcal{A} \text{
ist Sigmaalgebra und } S\subseteq \mathcal{A}\}\]</span></li>
</ol>
<h2 id="a8">Aufgabenblatt 08</h2>
<p><strong>Aufgabe 8.1 - Erwartungswert, Kovarianz und
Unabhängigkeit</strong></p>
<ol type="1">
<li>Seien <span class="math inline">\(X\)</span> und <span
class="math inline">\(Y\)</span> zwei Zufallsvariablen mit gemeinsamer
Dichte <span
class="math display">\[f^{X,Y}(x,y)=\frac{6}{7}(x+2y^2)\mathbf{1}_{[0,1]^2}(x,y).\]</span>
Man kann zeigen, dass die Dichte von <span
class="math inline">\(X\)</span> und der Erwartungswert von <span
class="math inline">\(Y\)</span> gegeben sind durch <span
class="math display">\[f^X(x)=\left(\frac{6}{7}x+\frac{4}{7}\right)\mathbf{1}_{[0,1]}(x)\]</span>
und <span class="math inline">\(E[Y]=\frac{9}{14}\)</span>. Berechnen
Sie <span class="math inline">\(E[X], E[X+Y], E[XY]\)</span> und <span
class="math inline">\(\text{Cov}(X,Y)\)</span>. Sind <span
class="math inline">\(X\)</span> und <span
class="math inline">\(Y\)</span> unabhängig? Lösung: Der Erwartungswert
von <span class="math inline">\(X\)</span> lässt sich wie folgt
bestimmen: <span class="math display">\[
\begin{aligned}
E[X]&amp;= \int_0^1 x\cdot f^X(x) \mathrm{d}x \\
&amp;= \int_0^1 x \cdot \left(\frac{6}{7}x+\frac{4}{7}\right)
\mathrm{d}x  &amp;&amp; \text{ohne }\mathbf{1} \text{ da nur von Null
bis Eins integriert wird}\\
&amp;=\int_0^1\frac{6}{7}x^2+\frac{4}{7}x \mathrm{d}x \\
&amp;=  \frac{6}{21}x^3+\frac{4}{14}x^2|_0^1 \\
&amp;=\frac{12}{42}+\frac{12}{42} \\
&amp;= \frac{24}{42} = \frac{4}{7}.
\end{aligned}
\]</span> Für den Erwartungswert <span
class="math inline">\(E[X+Y]\)</span> gilt: <span
class="math display">\[E[X+Y]
=E][X]+E[Y]=\frac{9}{14}+\frac{4}{7}=\frac{17}{14}.\]</span> Der
Erwartungswert <span class="math inline">\(E[XY]\)</span> lässt sich wie
folgt bestimmen: <span class="math display">\[
\begin{aligned}
E[XY]&amp;= \int_0^1\int_0^1 x\cdot y\cdot f^{XY}(x,y)
\mathrm{d}x\mathrm{d}y \\
&amp;=  \int_0^1\int_0^1 x\cdot y\cdot\frac{6}{7}(x+2y^2)
\mathrm{d}x\mathrm{d}y\\
&amp;=  \int_0^1\int_0^1
\frac{6}{7}x^2y+\frac{12}{7}y^3x  \mathrm{d}x\mathrm{d}y\\
&amp;=  \int_0^1\int_0^1 \frac{6}{7}x^2y \mathrm{d}x\mathrm{d}y \: + \:
\int_0^1\int_0^1 \frac{12}{7}y^3x  \mathrm{d}x\mathrm{d}y\\
&amp;=\int_0^1\left(\frac{6}{7}\int_0^1x^2y
\mathrm{d}x\right)\mathrm{d}y  \: + \:
\int_0^1\left(\frac{12}{7}\int_0^1y^3x \mathrm{d}x\right)\mathrm{d}y  \\
&amp;=\frac{6}{7}\int_0^1\left(\frac{1}{3}y\right)\mathrm{d}y  \: + \:
\frac{12}{7}\int_0^1\left(\frac{1}{2}y^3\right)\mathrm{d}y \\
&amp;= \frac{3}{21}+\frac{3}{14} = \frac{5}{14}.
\end{aligned}
\]</span> Die Kovarianz <span
class="math inline">\(\text{Cov}(X,Y)\)</span> lässt sich nun schnell
berechnen, mit <span class="math display">\[
\begin{aligned}
\text{Cov}(X,Y)]&amp;= E[XY]-E[X]E[Y] \\
&amp;= \frac{5}{14} -\frac{8}{14}\cdot\frac{9}{14} \\
&amp;= \frac{5}{14}-\frac{72}{196} = \frac{35}{98}-\frac{36}{98} \\
&amp;= -\frac{1}{98}
\end{aligned}
\]</span> Die beiden Zufallsvariablen sind un/abhängig, weil.?????</li>
<li>Sei <span class="math inline">\(X\sim\text{Poi}(\lambda)\)</span>
für ein <span class="math inline">\(\lambda&gt;0\)</span>. Wir
definieren<span class="math display">\[Y=\frac{1}{1+X} \quad \text{und}
\quad Z = \frac{X}{1+X}.\]</span> Bestimmen Sie <span
class="math inline">\(E[X]\)</span> und <span
class="math inline">\(E[Y]\)</span>. Lösung: Für <span
class="math inline">\(E[X]\)</span> gilt <span class="math display">\[
\begin{aligned}
E[X] &amp;= \sum_{k=1}^\infty k\cdot \frac{\lambda^k}{k!}e^{-\lambda} \\
&amp;=\frac{1}{e^\lambda}\sum_{k=1}^\infty k\cdot \frac{\lambda^k}{k!}
\\
&amp;=\frac{1}{e^\lambda}\sum_{k=1}^\infty  \frac{\lambda^k}{(k-1)!} \\
&amp;= \frac{1}{e^\lambda}\sum_{k=0}^\infty  \frac{\lambda^{k+1}}{(k)!}
\\
&amp;=  \frac{\lambda}{e^\lambda}\sum_{k=0}^\infty  \frac{\lambda^{k}}{(k)!}
&amp;&amp;(e^x = \sum_{n = 0}^\infty \frac{x^n}{n!})\\
&amp;= \frac{\lambda}{e^\lambda} e^\lambda = \lambda.
\end{aligned}
\]</span> Für <span class="math inline">\(E[Y]\)</span> gilt <span
class="math display">\[\begin{aligned} E[Y] &amp;= \sum_{k=1}^\infty
\frac{1}{1+k}^\cdot \frac{\lambda^k}{k!}e^{-\lambda} \\
&amp;=e^{-\lambda} \sum_{k=1}^\infty \frac{\lambda^k}{(k+1)!},
\end{aligned}
\]</span>da die Poisson-Verteilung mit wachsendem <span
class="math inline">\(k\)</span> schnell sehr klein wird, können wir die
Summe näherungsweise auf endliche viele Summanden beschränken.</li>
</ol>
<p><strong>Aufgabe 8.2 - Stochastische und fast-sichere
Konvergenz</strong> Wir betrachten den Wahrscheinlichkeitsraum <span
class="math inline">\((\Omega,\mathcal{A},P)=([0,1],\mathcal{B}_{[0,1],U_{[0,1]}})\)</span>
und definieren eine Folge von Zufallsvariablen <span
class="math inline">\(X_n: \Omega \to \mathbb{R}, \:
n\in\mathbb{N}\)</span>, durch <span
class="math display">\[X_n(\omega)=\begin{cases} n, \text{falls } 0
\leq\omega &lt;\frac{1}{n}\\ 0,\ \text{sonst.}\end{cases}\]</span>
Ferner sei <span class="math inline">\(X=0\)</span> mit
Wahrscheinlichkeit 1. Überprüfen Sie, ob</p>
<ol type="1">
<li><span class="math inline">\(\lim_{n \to \infty} E[X_n]=
E[X]\)</span> Lösung: Für den Erwartungswert <span
class="math inline">\(E[X_n]\)</span> gilt <span class="math display">\[
\begin{aligned}
E[X_n] &amp;= \int_0^1 x f(x) \mathrm{d}x \\
&amp;= \int_0^\frac{1}{n} n\cdot 1 \mathrm{d}x \\
&amp;= n \cdot \frac{1}{n} = 1.
\end{aligned}
\]</span> Somit ist <span class="math display">\[\lim_{n \to \infty}
E[X_n]= 1.\]</span> Für <span class="math inline">\(E[X]\)</span> gilt
<span class="math display">\[E[X]=0\cdot 1 = 0\neq 1 = \lim_{n \to
\infty} E[X_n].\]</span></li>
<li><span class="math inline">\(X_n \to X \text{ f.s}\)</span> Lösung:
Es muss überprüft werden, ob <span class="math display">\[P\left(\lim_{n
\to \infty} X_n(\omega)=X(\omega)=0\right)=1\]</span> gilt. Für jedes
<span class="math inline">\(\omega \in (0,1]\)</span> kann ich ein
Folgenglied <span class="math inline">\(n_0(\omega)\)</span> finden
sodas für alls kommenden <span class="math inline">\(n\)</span> gilt
<span class="math inline">\(\omega\geq \frac{1}{n}\)</span>. D.h. <span
class="math inline">\(\forall n \geq n_0: X_n(\omega)=0\)</span>. Ist
<span class="math inline">\(\omega = 0\)</span> dann gilt <span
class="math inline">\(\forall n: X_n(\omega)=n\)</span>. Bei <span
class="math inline">\(\omega=0\)</span> handelt es sich um eine
Nullmenge. Also gilt, dass für fast alle <span
class="math inline">\(\omega \in [0,1]\)</span> das <span
class="math inline">\(X_n(\omega)\)</span> gegen Null konvergiert außer
für <span class="math inline">\(\omega = 0\)</span> was eine Nullmenge
ist. Somit gilt <span class="math display">\[X_n \to X \text{
f.s}.\]</span></li>
<li><span class="math inline">\(X_n \overset{P}{\to} X\)</span> Lösung:
Es muss überprüft werden, ob <span class="math display">\[\lim_{n\to
\infty}P(|X_n-X|\geq \epsilon)=0 \quad \forall \epsilon \geq 0.\]</span>
Dies auf unsre Situation angewendet ergibt <span
class="math display">\[P(|X_n-0|\geq \epsilon)=P(|X_n|).\]</span> Hier
für gilt <span class="math display">\[\begin{aligned}
P(|X_n\geq \epsilon|)&amp;= P(0\leq\omega&lt;\frac{1}{n})\\
&amp;=\int_0^\frac{1}{n}1\mathrm{d}x = \frac{1}{n}\\
\Rightarrow \quad \ \lim_{n\to \infty}P(|X_n-X|\geq \epsilon)
&amp;=  \lim_{n\to \infty} \frac{1}{n} \\
&amp;=0.
\end{aligned}\]</span></li>
</ol>
<h2 id="cm">Concept-Map</h2>
<p>Der Versuch, die Beziehungen zwischen den obigen Inhalten grafisch
darzustellen. Klicke <a href="stmcm.html">hier für die Concept-Map</a>.
 </p>
<p> </p>
<hr />
<p><span class="footer"><em>Aktualisiert: 09.01.2025 -
Jakob</em></span></p>
</body>
</html>
